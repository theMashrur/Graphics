{"camera":{"position":[-1.7232953151034427,7.988399220575887,39.156298741702855],"target":[0,0,0],"nearClipping":0.1,"farClipping":1000,"projection":"Perspective","perspectiveFov":45,"orthographicFov":30},"model":{"mesh":"teapot","position":[0,-8,0],"rotationAxis":[1,0,0],"rotationAngle":-90,"scale":[1,1,1],"depthTest":"LESS","faceCulling":"","frontFace":"CCW","blendEnable":true,"blendOperation":"FUNC_ADD","srcColorBlendFactor":"SRC_ALPHA","dstColorBlendFactor":"ONE_MINUS_SRC_ALPHA","srcAlphaBlendFactor":"SRC_ALPHA","dstAlphaBlendFactor":"ONE_MINUS_SRC_ALPHA","textureFiltering":"LINEAR_MIPMAP_LINEAR","maxAnisotropy":"1"},"passes":{"Model":{"base":{"shaders":{"vertex":{"source":"#version 300 es\n\n// Vertex position in object space coordinates\nin vec3 vertexPosition;\n// Surface normal at the vertex in object space coordinates\nin vec3 vertexNormal;\n// Texture coordinates at that vertex\nin vec2 vertexTextureCoordinates;\n\n// Model matrix\nuniform mat4 mMatrix;\n// View matrix\nuniform mat4 vMatrix;\n// Projection matrix\nuniform mat4 pMatrix;\n\n// Light intensity\nuniform float lightIntensity;\n// Boolean indicating if the light is in camera space\nuniform bool lightInCamspace;\n\nuniform vec4 lightPosition;\n\n// Main program for each vertex\nvoid main() {\n  vec4 vertexCamSpace = vMatrix * mMatrix * vec4(vertexPosition, 1.0);\n  gl_Position = pMatrix * vertexCamSpace;\n}"},"fragment":{"source":"#version 300 es\n\n// For better performance less precision\nprecision highp float;\nout vec4 fragColor;\n\n// Main program for each fragment = pixel candidate\nvoid main() {\n  fragColor = vec4(1.0, 0.0, 0.0, 1.0);\n}"}},"uniforms":{"value":{"mMatrix":{"attachment":"Model Matrix"},"vMatrix":{"attachment":"View Matrix"},"pMatrix":{"attachment":"Projection Matrix"},"lightIntensity":{"value":[0]},"lightInCamspace":{"value":[0]},"lightPosition":{"value":[0,0,0,0]}}}}},"Quad":{"R2T":{"shaders":{"vertex":{"source":"#version 300 es\n\n// Vertex coordinates in object space for the render quad\nin vec3 vertexPosition;\n// Texture coordinate for this vertex and the render quad\nin vec2 vertexTextureCoordinates;\n\n// Texture coordinate needs to be passed on to the R2T fragment shader\nout vec2 fragmentTextureCoordinates;\n\n// Main program for each vertex of the render quad\nvoid main() {\n  gl_Position = vec4(vertexPosition, 1.0);\n  fragmentTextureCoordinates = vertexTextureCoordinates;\n}"},"fragment":{"source":"#version 300 es\n\nprecision highp float;\n\n// A texture sampling unit, which is bound to the render quad texture buffer\nuniform sampler2D textureRendered;\n\n// Texture coordinates coming from the vertex shader, interpolated through the rasterizer\nin vec2 fragmentTextureCoordinates;\nout vec4 fragColor;\n\n// Constants for the radial blur as defined in the spec\nconst float dMax = 0.3;\nconst int n = 12;\nconst float s[n] = float[](-0.10568, -0.07568, -0.042158, -0.02458, -0.01987456, -0.0112458, 0.0112458, 0.01987456, 0.02458, 0.042158, 0.07568, 0.10568);\n\n// Main program for each fragment of the render quad\nvoid main() {\n  // Calculate the normalized vector from the center of the texture to the current fragment, using normalized co-ordinates\n  vec2 center = vec2(0.5, 0.5);\n  vec2 p = center - fragmentTextureCoordinates;\n  vec2 pNorm = normalize(p);\n\n  // Sample the texture at multiple positions and sum the values according to the formula\n  vec3 sumAccumulator = vec3(0.0);\n  for (int i = 0; i < n; i++) {\n    float d = s[i] * dMax;\n    vec2 sumTerm = fragmentTextureCoordinates + pNorm * d;\n    sumAccumulator += texture(textureRendered, sumTerm.xy).xyz;\n  }\n\n  // Calculate the blurred color value and set the output color, making sure to divide by n, as in the formula\n  vec3 rgb_blur = sumAccumulator / float(n);\n  fragColor = vec4(rgb_blur, 1.0);\n}"}},"uniforms":{"value":{"textureRendered":{"attachment":"Model/base Pass color"}}}}}},"output":{"image":"Quad/R2T Pass color"}}